{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b59cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do Byte Pair Encoding (BPE) on a text file using the tiktoken library-used by OpenAI.\n",
    "import importlib\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5402d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktoken = tiktoken.get_encoding(\"gpt2\")\n",
    "#This is similar to the SimpleTokenizer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf68494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [1212, 318, 257, 1332, 13, 770, 318, 691, 257, 1332, 5633, 930, 27, 437, 1659, 5239, 29, 91]\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a test. This is only a test ? |<endoftext>|\"\n",
    "tokens = tiktoken.encode(text)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7542e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: This is a test. This is only a test ? |<endoftext>|\n"
     ]
    }
   ],
   "source": [
    "string = tiktoken.decode(tokens)\n",
    "print(\"String:\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52fff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens with unknown word: [1212, 318, 257, 1332, 13, 770, 318, 691, 257, 1332, 5633, 930, 27, 437, 1659, 5239, 29, 91, 15837, 824, 67, 8461, 16993, 73]\n"
     ]
    }
   ],
   "source": [
    "# Lets see how this tokenizer works with unkown words\n",
    "token = tiktoken.encode(\"This is a test. This is only a test ? |<endoftext>| AKssdniwdj\")\n",
    "print(\"Tokens with unknown word:\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fab3dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: This is a test. This is only a test ? |<endoftext>|\n"
     ]
    }
   ],
   "source": [
    "string = tiktoken.decode(tokens)\n",
    "print(\"String:\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b1677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped non-text file: .DS_Store\n"
     ]
    }
   ],
   "source": [
    "# Now we will create input target pairs for training. This is the last step before creating vector embeddings.\n",
    "#given a sentence, the input goes to the LLM and the target will be the last token to be predicted. the input increase over time as targets of the previous step are added to the input.\n",
    "import os\n",
    "data_folder = \"data\"\n",
    "raw_texts = []\n",
    "for filename in os.listdir(data_folder):\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_texts.append(f.read())\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Skipped non-text file: {filename}\")\n",
    "\n",
    "raw_text = \"\\n\".join(raw_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f664c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text length: 76064\n"
     ]
    }
   ],
   "source": [
    "enc_text = tiktoken.encode(raw_text)\n",
    "print(\"Encoded text length:\", len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c970c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: [31478, 17034, 69, 16, 59, 504, 72, 59, 504, 291]\n",
      "Target tokens: [17034, 69, 16, 59, 504, 72, 59, 504, 291, 6024]\n"
     ]
    }
   ],
   "source": [
    "context_size = 10 # length of the input sequence\n",
    "\n",
    "#the input is the first 10 tokens [1,2,3,4,5,6,7,8,9,10] and the target is the next token [11]\n",
    "\n",
    "x = enc_text[:context_size]\n",
    "y = enc_text[1:context_size+1]\n",
    "print(\"Input tokens:\", x)\n",
    "print(\"Target tokens:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4958369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens 1: [17034, 69, 16, 59, 504, 72, 59, 504, 291, 6024]\n",
      "Target tokens 1: 1065\n",
      "Input tokens 2: [69, 16, 59, 504, 72, 59, 504, 291, 6024, 1065]\n",
      "Target tokens 2: 4309\n",
      "Input tokens 3: [16, 59, 504, 72, 59, 504, 291, 6024, 1065, 4309]\n",
      "Target tokens 3: 59\n",
      "Input tokens 4: [59, 504, 72, 59, 504, 291, 6024, 1065, 4309, 59]\n",
      "Target tokens 4: 66\n",
      "Input tokens 5: [504, 72, 59, 504, 291, 6024, 1065, 4309, 59, 66]\n",
      "Target tokens 5: 25634\n",
      "Input tokens 6: [72, 59, 504, 291, 6024, 1065, 4309, 59, 66, 25634]\n",
      "Target tokens 6: 433\n",
      "Input tokens 7: [59, 504, 291, 6024, 1065, 4309, 59, 66, 25634, 433]\n",
      "Target tokens 7: 69\n",
      "Input tokens 8: [504, 291, 6024, 1065, 4309, 59, 66, 25634, 433, 69]\n",
      "Target tokens 8: 2078\n",
      "Input tokens 9: [291, 6024, 1065, 4309, 59, 66, 25634, 433, 69, 2078]\n",
      "Target tokens 9: 1828\n",
      "Input tokens 10: [6024, 1065, 4309, 59, 66, 25634, 433, 69, 2078, 1828]\n",
      "Target tokens 10: 198\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size +1):\n",
    "    x = enc_text[i:i + context_size]\n",
    "    y = enc_text[i + context_size]\n",
    "    print(f\"Input tokens {i}:\", x)\n",
    "    print(f\"Target tokens {i}:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02aa622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
