{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will implement a GPT2 model from scratch using PyTorch.\n",
    "# This is a simplified version and does not include all the optimizations and features of the original GPT2.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "GPT_CONFIG_124M = {   \n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ed9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29a7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f9acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd34215",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56cbad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1a1f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd4afdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "batch =  torch.tensor([[6109, 3626, 6100,  345],\n",
    "        [6109, 1110, 6622,  257]])\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "078773cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a45036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is because of weight tying, where the output layer uses the same weights as the input embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "788726d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0599ba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4eaf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0553b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated indices: tensor([[15496,    11,   314,   716, 46302,  5748, 32746, 18641, 24436, 21950,\n",
      "         13748, 50105,  5662,  4266]])\n",
      "Generated text: [[329, 425, 487, 580, 444, 565, 212, 316, 565, 159, 180, 111, 84, 198]]\n"
     ]
    }
   ],
   "source": [
    "encoded: [15496, 11, 314, 716] # Example usage of the generate_text_simple function\n",
    "encoded = torch.tensor([[15496, 11, 314, 716]])  # Example input\n",
    "generated = generate_text_simple(model, encoded, max_new_tokens=10, context_size=GPT_CONFIG_124M[\"context_length\"])\n",
    "print(\"Generated indices:\", generated)\n",
    "print(\"Generated text:\", model.tok_emb.weight[generated].argmax(dim=-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b59c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will produce gibberish text because the model is not trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8638e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we predict the LLM loss - We use cross-entropy loss, which is a common loss function for classification tasks.\n",
    "def compute_loss(model, idx):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "    logits = model(idx)  # Get the logits for the input indices\n",
    "    # Shift the indices to the right to create labels\n",
    "    labels = idx[:, 1:]  # Shifted by one position\n",
    "    logits = logits[:, :-1, :]  # Remove the last token's logits\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a1064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped non-text file: .DS_Store\n"
     ]
    }
   ],
   "source": [
    "# We will now evaluate this model on the text dataset.\n",
    "import os\n",
    "data_folder = \"Data_Preprocessing/data\"\n",
    "raw_texts = []\n",
    "for filename in os.listdir(data_folder):\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                raw_texts.append(f.read())\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Skipped non-text file: {filename}\")\n",
    "\n",
    "raw_text = \"\\n\".join(raw_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c790ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text length: 274775\n",
      "First 100 characters of raw text: \n",
      "In my younger and more vulnerable years my father gave me some advice\\\n",
      "that I've been turning over \n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text length:\", len(raw_text))\n",
    "print(\"First 100 characters of raw text:\", raw_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5477e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "468f2f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in raw text: 274775\n",
      "Total tokens in raw text: 75876\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(raw_text)\n",
    "print(\"Total characters in raw text:\", total_characters)\n",
    "\n",
    "total_tokens = len(tokenizer.encode(raw_text))\n",
    "print(\"Total tokens in raw text:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1debbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing a dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text,tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1:i + 1 + max_length]\n",
    "            self.input_ids.append(input_chunk)\n",
    "            self.target_ids.append(target_chunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59187527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(text, batch_size = 4, max_length = 256, stride = 128, shuffle = True, drop_last = True, num_workers = 0):\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = TextDataset(text, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03a34585",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "train_size = int(len(raw_text) * train_ratio)\n",
    "train_text = raw_text[:train_size]\n",
    "test_text = raw_text[train_size:]\n",
    "train_dataloader = create_dataloader(train_text, batch_size=4, max_length=GPT_CONFIG_124M[\"context_length\"], stride=GPT_CONFIG_124M[\"context_length\"], drop_last=True, shuffle=True, num_workers=0)\n",
    "test_dataloader = create_dataloader(test_text, batch_size=4, max_length=GPT_CONFIG_124M[\"context_length\"], stride=GPT_CONFIG_124M[\"context_length\"], drop_last=False, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3466109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d703b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = torch.stack(input_batch).to(device)\n",
    "    target_batch = torch.stack(target_batch).to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_batch.view(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cb935e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(dataloader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = num_batches or len(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss\n",
    "            \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97664fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 11.0000\n",
      "Average test loss: 10.9991\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    # Calculate loss on the training set\n",
    "    train_loss = calc_loss_loader(train_dataloader, model, device)\n",
    "    print(f\"Average training loss: {train_loss:.4f}\")\n",
    "    test_loss = calc_loss_loader(test_dataloader, model, device)\n",
    "    print(f\"Average test loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74a0b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_dataloader, test_dataloader, device):\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for input_batch, target_batch in train_dataloader:\n",
    "            train_loss += calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        for input_batch, target_batch in test_dataloader:\n",
    "            val_loss += calc_loss_batch(input_batch, target_batch, model, device)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "929b3b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will implement a simple training loop to train the model on the dataset.\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    token_seen, global_step = 0, -1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            input_batch = torch.stack(input_batch).to(device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                model.eval()\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(token_seen)\n",
    "                print(f\"Epoch {epoch+1}, Step {global_step}, \"\n",
    "                      f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                      f\"Tokens Seen: {token_seen:,}\")\n",
    "\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9be3d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0, Train Loss: 124.1960, Val Loss: 35.8273, Tokens Seen: 4,096\n",
      "Epoch 1, Step 5, Train Loss: 91.2234, Val Loss: 26.6663, Tokens Seen: 24,576\n",
      "Epoch 1, Step 10, Train Loss: 87.1451, Val Loss: 25.8632, Tokens Seen: 45,056\n",
      "Epoch 2, Step 15, Train Loss: 86.3001, Val Loss: 25.9666, Tokens Seen: 65,536\n",
      "Epoch 2, Step 20, Train Loss: 84.3708, Val Loss: 25.4944, Tokens Seen: 86,016\n",
      "Epoch 2, Step 25, Train Loss: 83.2135, Val Loss: 25.1542, Tokens Seen: 106,496\n",
      "Epoch 3, Step 30, Train Loss: 82.9197, Val Loss: 24.9479, Tokens Seen: 126,976\n",
      "Epoch 3, Step 35, Train Loss: 82.1472, Val Loss: 24.9598, Tokens Seen: 147,456\n",
      "Epoch 3, Step 40, Train Loss: 81.3860, Val Loss: 24.7945, Tokens Seen: 167,936\n",
      "Epoch 4, Step 45, Train Loss: 80.9666, Val Loss: 24.6994, Tokens Seen: 188,416\n",
      "Epoch 4, Step 50, Train Loss: 80.4082, Val Loss: 24.5225, Tokens Seen: 208,896\n",
      "Epoch 4, Step 55, Train Loss: 79.6139, Val Loss: 24.4251, Tokens Seen: 229,376\n",
      "Epoch 5, Step 60, Train Loss: 78.7850, Val Loss: 24.3194, Tokens Seen: 249,856\n",
      "Epoch 5, Step 65, Train Loss: 78.5394, Val Loss: 24.2401, Tokens Seen: 270,336\n",
      "Epoch 6, Step 70, Train Loss: 78.3593, Val Loss: 24.1568, Tokens Seen: 290,816\n",
      "Epoch 6, Step 75, Train Loss: 77.9329, Val Loss: 24.0657, Tokens Seen: 311,296\n",
      "Epoch 6, Step 80, Train Loss: 77.4397, Val Loss: 24.0183, Tokens Seen: 331,776\n",
      "Epoch 7, Step 85, Train Loss: 77.0643, Val Loss: 23.8287, Tokens Seen: 352,256\n",
      "Epoch 7, Step 90, Train Loss: 76.5565, Val Loss: 23.8198, Tokens Seen: 372,736\n",
      "Epoch 7, Step 95, Train Loss: 75.8197, Val Loss: 23.6480, Tokens Seen: 393,216\n",
      "Epoch 8, Step 100, Train Loss: 75.2294, Val Loss: 23.4649, Tokens Seen: 413,696\n",
      "Epoch 8, Step 105, Train Loss: 74.7149, Val Loss: 23.3692, Tokens Seen: 434,176\n",
      "Epoch 8, Step 110, Train Loss: 74.0392, Val Loss: 23.1471, Tokens Seen: 454,656\n",
      "Epoch 9, Step 115, Train Loss: 73.6421, Val Loss: 23.0708, Tokens Seen: 475,136\n",
      "Epoch 9, Step 120, Train Loss: 72.3233, Val Loss: 22.9276, Tokens Seen: 495,616\n",
      "Epoch 9, Step 125, Train Loss: 71.7606, Val Loss: 22.8429, Tokens Seen: 516,096\n",
      "Epoch 10, Step 130, Train Loss: 71.7092, Val Loss: 22.7989, Tokens Seen: 536,576\n",
      "Epoch 10, Step 135, Train Loss: 71.3759, Val Loss: 22.7591, Tokens Seen: 557,056\n",
      "Epoch 11, Step 140, Train Loss: 70.2900, Val Loss: 22.5284, Tokens Seen: 577,536\n",
      "Epoch 11, Step 145, Train Loss: 69.6970, Val Loss: 22.4162, Tokens Seen: 598,016\n",
      "Epoch 11, Step 150, Train Loss: 69.0226, Val Loss: 22.4255, Tokens Seen: 618,496\n",
      "Epoch 12, Step 155, Train Loss: 68.8048, Val Loss: 22.3664, Tokens Seen: 638,976\n",
      "Epoch 12, Step 160, Train Loss: 68.6516, Val Loss: 22.3903, Tokens Seen: 659,456\n",
      "Epoch 12, Step 165, Train Loss: 67.6361, Val Loss: 22.2387, Tokens Seen: 679,936\n",
      "Epoch 13, Step 170, Train Loss: 67.3948, Val Loss: 22.1207, Tokens Seen: 700,416\n",
      "Epoch 13, Step 175, Train Loss: 66.6561, Val Loss: 22.1287, Tokens Seen: 720,896\n",
      "Epoch 13, Step 180, Train Loss: 66.4346, Val Loss: 22.0721, Tokens Seen: 741,376\n",
      "Epoch 14, Step 185, Train Loss: 65.9669, Val Loss: 22.1396, Tokens Seen: 761,856\n",
      "Epoch 14, Step 190, Train Loss: 65.6436, Val Loss: 22.1041, Tokens Seen: 782,336\n",
      "Epoch 14, Step 195, Train Loss: 64.9564, Val Loss: 22.0179, Tokens Seen: 802,816\n",
      "Epoch 15, Step 200, Train Loss: 64.4793, Val Loss: 21.9433, Tokens Seen: 823,296\n",
      "Epoch 15, Step 205, Train Loss: 63.9468, Val Loss: 21.9369, Tokens Seen: 843,776\n",
      "Epoch 16, Step 210, Train Loss: 63.6621, Val Loss: 21.9331, Tokens Seen: 864,256\n",
      "Epoch 16, Step 215, Train Loss: 63.5659, Val Loss: 21.9354, Tokens Seen: 884,736\n",
      "Epoch 16, Step 220, Train Loss: 62.9161, Val Loss: 21.8427, Tokens Seen: 905,216\n",
      "Epoch 17, Step 225, Train Loss: 62.6512, Val Loss: 21.9458, Tokens Seen: 925,696\n",
      "Epoch 17, Step 230, Train Loss: 62.3688, Val Loss: 21.9362, Tokens Seen: 946,176\n",
      "Epoch 17, Step 235, Train Loss: 61.7147, Val Loss: 21.8070, Tokens Seen: 966,656\n",
      "Epoch 18, Step 240, Train Loss: 61.3105, Val Loss: 21.8185, Tokens Seen: 987,136\n",
      "Epoch 18, Step 245, Train Loss: 60.8249, Val Loss: 21.7672, Tokens Seen: 1,007,616\n",
      "Epoch 18, Step 250, Train Loss: 60.1956, Val Loss: 21.8102, Tokens Seen: 1,028,096\n",
      "Epoch 19, Step 255, Train Loss: 60.1895, Val Loss: 21.7473, Tokens Seen: 1,048,576\n",
      "Epoch 19, Step 260, Train Loss: 60.0424, Val Loss: 21.9001, Tokens Seen: 1,069,056\n",
      "Epoch 19, Step 265, Train Loss: 59.2560, Val Loss: 21.7093, Tokens Seen: 1,089,536\n",
      "Epoch 20, Step 270, Train Loss: 58.8980, Val Loss: 21.8863, Tokens Seen: 1,110,016\n",
      "Epoch 20, Step 275, Train Loss: 58.6828, Val Loss: 21.8454, Tokens Seen: 1,130,496\n",
      "Training completed in 137.71 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 20\n",
    "train_losses, val_losses, track_tokens_seen = train_model_simple(\n",
    "    model, train_dataloader, test_dataloader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8a66f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the training and validation losses vs epochs\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(train_losses, val_losses, track_tokens_seen):\n",
    "    # Convert any torch.Tensor entries into Python floats/ints\n",
    "    xs = [\n",
    "        x.cpu().item() if isinstance(x, torch.Tensor) else x\n",
    "        for x in track_tokens_seen\n",
    "    ]\n",
    "    ys_train = [\n",
    "        t.cpu().item() if isinstance(t, torch.Tensor) else t\n",
    "        for t in train_losses\n",
    "    ]\n",
    "    ys_val = [\n",
    "        v.cpu().item() if isinstance(v, torch.Tensor) else v\n",
    "        for v in val_losses\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(xs, ys_train, label='Training Loss', color='blue')\n",
    "    plt.plot(xs, ys_val,   label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Tokens Seen')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "plot_losses(train_losses, val_losses, track_tokens_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31ca1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict()}, \"gpt2_model.pth\")\n",
    "# Load the model\n",
    "# checkpoint = torch.load(\"gpt2_model.pth\")\n",
    "# model.load_state_dict(checkpoint[\"model\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "# model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e674ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 4.1551\n",
      "Average test loss: 5.4460\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    # Calculate loss on the training set\n",
    "    train_loss = calc_loss_loader(train_dataloader, model, device)\n",
    "    print(f\"Average training loss: {train_loss:.4f}\")\n",
    "    test_loss = calc_loss_loader(test_dataloader, model, device)\n",
    "    print(f\"Average test loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c912d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
